{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da4da7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 7.930162, W: 0.613801, b: -0.503987\n",
      "step: 20, cost: 0.307430, W: 1.356400, b: -0.200258\n",
      "step: 40, cost: 0.268346, W: 1.336299, b: -0.114206\n",
      "step: 60, cost: 0.234348, W: 1.314289, b: -0.034683\n",
      "step: 80, cost: 0.204658, W: 1.293706, b: 0.039629\n",
      "step: 100, cost: 0.178730, W: 1.274471, b: 0.109073\n",
      "step: 120, cost: 0.156086, W: 1.256495, b: 0.173970\n",
      "step: 140, cost: 0.136311, W: 1.239697, b: 0.234616\n",
      "step: 160, cost: 0.119041, W: 1.223999, b: 0.291291\n",
      "step: 180, cost: 0.103960, W: 1.209329, b: 0.344254\n",
      "step: 200, cost: 0.090789, W: 1.195620, b: 0.393748\n",
      "step: 220, cost: 0.079286, W: 1.182809, b: 0.440001\n",
      "step: 240, cost: 0.069241, W: 1.170837, b: 0.483225\n",
      "step: 260, cost: 0.060469, W: 1.159648, b: 0.523618\n",
      "step: 280, cost: 0.052808, W: 1.149193, b: 0.561366\n",
      "step: 300, cost: 0.046118, W: 1.139422, b: 0.596642\n",
      "step: 320, cost: 0.040275, W: 1.130291, b: 0.629607\n",
      "step: 340, cost: 0.035172, W: 1.121758, b: 0.660413\n",
      "step: 360, cost: 0.030716, W: 1.113784, b: 0.689202\n",
      "step: 380, cost: 0.026825, W: 1.106333, b: 0.716106\n",
      "step: 400, cost: 0.023426, W: 1.099369, b: 0.741247\n",
      "step: 420, cost: 0.020458, W: 1.092861, b: 0.764742\n",
      "step: 440, cost: 0.017866, W: 1.086779, b: 0.786699\n",
      "step: 460, cost: 0.015603, W: 1.081096, b: 0.807217\n",
      "step: 480, cost: 0.013626, W: 1.075785, b: 0.826392\n",
      "step: 500, cost: 0.011900, W: 1.070822, b: 0.844310\n",
      "step: 520, cost: 0.010392, W: 1.066184, b: 0.861056\n",
      "step: 540, cost: 0.009076, W: 1.061849, b: 0.876704\n",
      "step: 560, cost: 0.007926, W: 1.057799, b: 0.891328\n",
      "step: 580, cost: 0.006922, W: 1.054013, b: 0.904994\n",
      "step: 600, cost: 0.006045, W: 1.050476, b: 0.917765\n",
      "step: 620, cost: 0.005279, W: 1.047170, b: 0.929700\n",
      "step: 640, cost: 0.004610, W: 1.044081, b: 0.940853\n",
      "step: 660, cost: 0.004026, W: 1.041194, b: 0.951276\n",
      "step: 680, cost: 0.003516, W: 1.038496, b: 0.961016\n",
      "step: 700, cost: 0.003070, W: 1.035975, b: 0.970118\n",
      "step: 720, cost: 0.002681, W: 1.033619, b: 0.978624\n",
      "step: 740, cost: 0.002342, W: 1.031417, b: 0.986573\n",
      "step: 760, cost: 0.002045, W: 1.029360, b: 0.994002\n",
      "step: 780, cost: 0.001786, W: 1.027437, b: 1.000944\n",
      "step: 800, cost: 0.001560, W: 1.025640, b: 1.007431\n",
      "step: 820, cost: 0.001362, W: 1.023961, b: 1.013493\n",
      "step: 840, cost: 0.001190, W: 1.022392, b: 1.019159\n",
      "step: 860, cost: 0.001039, W: 1.020925, b: 1.024453\n",
      "step: 880, cost: 0.000907, W: 1.019555, b: 1.029401\n",
      "step: 900, cost: 0.000792, W: 1.018274, b: 1.034024\n",
      "step: 920, cost: 0.000692, W: 1.017077, b: 1.038345\n",
      "step: 940, cost: 0.000604, W: 1.015959, b: 1.042383\n",
      "step: 960, cost: 0.000528, W: 1.014914, b: 1.046156\n",
      "step: 980, cost: 0.000461, W: 1.013937, b: 1.049682\n",
      "step: 1000, cost: 0.000402, W: 1.013024, b: 1.052978\n",
      "step: 1020, cost: 0.000351, W: 1.012171, b: 1.056057\n",
      "step: 1040, cost: 0.000307, W: 1.011374, b: 1.058935\n",
      "step: 1060, cost: 0.000268, W: 1.010629, b: 1.061625\n",
      "step: 1080, cost: 0.000234, W: 1.009933, b: 1.064138\n",
      "step: 1100, cost: 0.000204, W: 1.009282, b: 1.066487\n",
      "step: 1120, cost: 0.000179, W: 1.008675, b: 1.068682\n",
      "step: 1140, cost: 0.000156, W: 1.008107, b: 1.070733\n",
      "step: 1160, cost: 0.000136, W: 1.007576, b: 1.072649\n",
      "step: 1180, cost: 0.000119, W: 1.007080, b: 1.074440\n",
      "step: 1200, cost: 0.000104, W: 1.006616, b: 1.076114\n",
      "step: 1220, cost: 0.000091, W: 1.006183, b: 1.077679\n",
      "step: 1240, cost: 0.000079, W: 1.005778, b: 1.079141\n",
      "step: 1260, cost: 0.000069, W: 1.005399, b: 1.080507\n",
      "step: 1280, cost: 0.000060, W: 1.005046, b: 1.081784\n",
      "step: 1300, cost: 0.000053, W: 1.004715, b: 1.082977\n",
      "step: 1320, cost: 0.000046, W: 1.004406, b: 1.084092\n",
      "step: 1340, cost: 0.000040, W: 1.004118, b: 1.085134\n",
      "step: 1360, cost: 0.000035, W: 1.003848, b: 1.086107\n",
      "step: 1380, cost: 0.000031, W: 1.003596, b: 1.087017\n",
      "step: 1400, cost: 0.000027, W: 1.003361, b: 1.087867\n",
      "step: 1420, cost: 0.000023, W: 1.003141, b: 1.088662\n",
      "step: 1440, cost: 0.000020, W: 1.002935, b: 1.089404\n",
      "step: 1460, cost: 0.000018, W: 1.002743, b: 1.090099\n",
      "step: 1480, cost: 0.000016, W: 1.002563, b: 1.090747\n",
      "step: 1500, cost: 0.000014, W: 1.002395, b: 1.091353\n",
      "step: 1520, cost: 0.000012, W: 1.002238, b: 1.091919\n",
      "step: 1540, cost: 0.000010, W: 1.002092, b: 1.092448\n",
      "step: 1560, cost: 0.000009, W: 1.001955, b: 1.092943\n",
      "step: 1580, cost: 0.000008, W: 1.001827, b: 1.093405\n",
      "step: 1600, cost: 0.000007, W: 1.001707, b: 1.093837\n",
      "step: 1620, cost: 0.000006, W: 1.001595, b: 1.094241\n",
      "step: 1640, cost: 0.000005, W: 1.001491, b: 1.094618\n",
      "step: 1660, cost: 0.000005, W: 1.001393, b: 1.094970\n",
      "step: 1680, cost: 0.000004, W: 1.001302, b: 1.095300\n",
      "step: 1700, cost: 0.000004, W: 1.001217, b: 1.095608\n",
      "step: 1720, cost: 0.000003, W: 1.001137, b: 1.095895\n",
      "step: 1740, cost: 0.000003, W: 1.001063, b: 1.096164\n",
      "step: 1760, cost: 0.000002, W: 1.000993, b: 1.096415\n",
      "step: 1780, cost: 0.000002, W: 1.000928, b: 1.096650\n",
      "step: 1800, cost: 0.000002, W: 1.000867, b: 1.096869\n",
      "step: 1820, cost: 0.000002, W: 1.000811, b: 1.097074\n",
      "step: 1840, cost: 0.000001, W: 1.000757, b: 1.097266\n",
      "step: 1860, cost: 0.000001, W: 1.000708, b: 1.097445\n",
      "step: 1880, cost: 0.000001, W: 1.000661, b: 1.097612\n",
      "step: 1900, cost: 0.000001, W: 1.000618, b: 1.097768\n",
      "step: 1920, cost: 0.000001, W: 1.000578, b: 1.097914\n",
      "step: 1940, cost: 0.000001, W: 1.000540, b: 1.098051\n",
      "step: 1960, cost: 0.000001, W: 1.000505, b: 1.098179\n",
      "step: 1980, cost: 0.000001, W: 1.000471, b: 1.098298\n",
      "step: 2000, cost: 0.000000, W: 1.000441, b: 1.098409\n",
      "y: 6.100612\n",
      "y: 2.599070\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "rng = np.random\n",
    "\n",
    "# x, y 데이터\n",
    "x_train = [1,2,3,4,5]\n",
    "y_train = [2.1,3.1,4.1,5.1,6.1]\n",
    "\n",
    "W = tf.Variable(rng.randn(), name='weight')\n",
    "b = tf.Variable(rng.randn(), name='bias')\n",
    "\n",
    "\n",
    "# Wx+b 일차원 함수\n",
    "def linear(x):\n",
    "    return x * W + b\n",
    "\n",
    "# 실제 값과 hypothesis 사이 cost\n",
    "def findcost(hypothesis, y):\n",
    "    return tf.reduce_mean(tf.square(hypothesis- y))\n",
    "\n",
    "#minimize cost\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "def run():\n",
    "    with tf.GradientTape() as g:\n",
    "        hypothesis = linear(x_train)\n",
    "        cost = findcost(hypothesis, y_train)\n",
    "    #gradient 계산\n",
    "    gradients = g.gradient(cost, [W, b])\n",
    "    #update\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "for step in range(2001):\n",
    "    # run함수를 실행하여 W, b값 업데이트\n",
    "    run()\n",
    "    if step % 20 == 0:\n",
    "        hypothesis = linear(x_train)\n",
    "        cost = findcost(hypothesis, y_train)\n",
    "        print(\"step: %i, cost: %f, W: %f, b: %f\" % (step, cost, W, b))\n",
    "\n",
    "#2000번을 돌려서 얻은 Wx+b함수에 값을 대입하여 y를 예측해보자 \n",
    "print(\"y: %f\" % linear(5))\n",
    "print(\"y: %f\" % linear(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6a01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
